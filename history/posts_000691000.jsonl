{"id": "nu7RgB4krMXv_zHDJqzRVg37Mfz_bB6quY5GVpXvQ58", "title": "Funding Friday: Storied Hats", "body": "If I am going to be outside much, I need to wear a hat to keep the sun off my face. My light skin doesn‚Äôt react well to the sun. I like baseball-style hats, but I don‚Äôt like wearing logos.\n\nSo [this Kickstarter project](https://www.kickstarter.com/projects/storiedhats/hats-from-food-waste-algae-and-cactus) got my attention. Fun stylish hats without logos, made with sustainable materials. Right up my alley. I backed it immediately.\n\nYou can watch the video [here](https://www.kickstarter.com/projects/storiedhats/hats-from-food-waste-algae-and-cactus).\n", "timestamp": 1621595256, "digest": "GsgN5g2rKA-wnDNbqAeBGfZeAhakarTxtqw92BdhEMw", "contributor": "0xB8332710AB60A1B2e8FE6D775d83524C9E0cE136"}
{"id": "UTbTtkqTfvXf4JDg4DvEykfowPw4CcMqdqie9UZgqBU", "title": "Textures Of A Long Forgotten Assumption ‚Äî LIVE NOW üî¥", "body": "Welcome to the official release of ***Textures Of A Long Forgotten Assumption*** ‚Äî my third album. \n\nThis 9-song body of work explores the fundamental beliefs we all have and don't dare question. What happens when we do? \n\nThe release of this project aims to rip open some of those deeply held beliefs we have around music ‚Äî what music is, how we value it, and how it‚Äôs ‚Äúsupposed to be‚Äù distributed. \n\nThis release is broken down into 3 sections: **The Canon, The Collectibles, and The Copies**. *To learn more about my thoughts behind this release mix, [read my previous essay](https://chaim.mirror.xyz/0SRGluR6sYweDWV0qmgF6V1wsN0BvEKsvCVOZCFX7yU).* \n\n### Here‚Äôs what‚Äôs happening:\n\n- There are 5 one-of-one *canon*ical NFTs on auction **below**\n- There are 9 NFT *collectibles* now [**available on Rarible**](https://rarible.com/chaim), which are walked through in detail below \n- There are 1000 album bundle *copies* [**now available on my online shop**](https://ko-fi.com/s/794a026bac), also walked through below \n\n### All collectors of any of the above will receive: \n\n- a private download of the *Textures Of A Long Forgotten Assumptions* album's songs and artwork\n- one (1) invitation into the *Homemade Universe* discord server ‚Äî my private online community. \n- one (1) entry into the *Flavors Feature Contest*. More on this below. \n\n## The full *Textures Of A Long Forgotten Assumption* tracklist is:\n1. Form\n2. Tear\n3. Sand\n4. Red Balloons\n5. Crazy\n6. Island\n7. Flavors (unfinished)\n8. Paint (unfinished)\n9. Untitled (unfinished)\n\nAs you can see, **three of the nine songs are unfinished**. I need your help to finish them, and you can see how in the *Collectibles* section below. \n\nLet‚Äôs begin...\n\n![](https://images.mirror-media.xyz/publication-images/406d2f77-5164-4980-8fc6-e991ed8bfdc9.jpg?height=3000&width=3000)\n\n\n# THE CANON\n\nOn auction are 4 one-of-one [Catalog NFTs](https://beta.catalog.works/chaim) for tracks 3 thru 6 ‚Äî *Sand*, *Red Balloons*, *Crazy* and *Island*. There is also a one-of-one Zora NFT for the official *Form* music video, auctioning off on Zora. \n\nYou can see who the recipients are for each of the 4 Catalog NFTs being auctioned below. These are the collaborators (writers, producers, engineers) I created this music with. \n\n## Track No. 3 ‚Äî Sand\n\n*Sand* is written by Danny Majic + myself, and produced by Danny Majic.\n\nThis was the first song Danny and I ever wrote together, the very day we met each other. This was also the very first song I wrote after a 10-day cross-country solo drive from Montreal, Canada to Los Angeles, California. \n\n[Token #3166](auction://0xabEFBc9fD2F806065b4f3C237d4b59D9A97Bcac7?network=mainnet&tokenId=3166)\n\n## Track No. 4 ‚Äî Red Balloons\n\n*Red Balloons* is written by Hayley Gene Penner, Jason Yik Nam Wu + myself, and produced by Rabitt.\n\nThis is the first song I've ever released with a co-written top-line. I've always found it difficult to write lyrics and melody with others, but Hayley is a great friend and we truly found a shared energy on this one. And Rabitt always brings the goods. \n\n[Token #3167](auction://0xabEFBc9fD2F806065b4f3C237d4b59D9A97Bcac7?network=mainnet&tokenId=3167)\n\n## Track No. 5 ‚Äî Crazy\n\n*Crazy* is written by Danny Majic + myself, and produced by Danny Majic.\n\nWe wrote this song together at a songwriting camp in Nashville, Tennessee. It was the first ever *Really Fun Camp* organized by Rabitt. \n\n[Token #3168](auction://0xabEFBc9fD2F806065b4f3C237d4b59D9A97Bcac7?network=mainnet&tokenId=3168)\n\n## Track No. 6 ‚Äî Island\n\n*Island* is written by Jason Yik Nam Wu + myself, and produced by Rabitt.\n\nWe wrote this song together in Jason's studio in Silverlake, Los Angeles. Attached to said studio was the very house we were both living in at the time. This was the last song we wrote together, before I left for Montreal when the pandemic began. A version of the song was first released on streaming platforms in May 2020, on a charity album raising money for MusiCares' Covid Relief Fund. \n\n[Token #3169](auction://0xabEFBc9fD2F806065b4f3C237d4b59D9A97Bcac7?network=mainnet&tokenId=3169)\n\nAs you can see in the auctions above above, **5% of funds received are going towards my private community *Homemade Universe*‚Äôs shared treasury**. These funds will be used in future co-creative projects together. Since all collectors + purchasers gain access to *Homemade Universe*, 5% of this project‚Äôs proceeds are funnelling into a community that you are co-creator and co-owner of. \n\n## Form ‚Äî The Official Music Video \n\nThe official music video for \"Form\" is [**now up for auction on Zora**](https://zora.co/chaim/3172), filmed + edited by myself while stuck in a quarantine hotel in Montreal in May 2020. ü•Ω\n\n*Form* is written by Jason Yik Nam Wu + myself, and produced by Rabitt.\n\nThe reserve bid is 0.5 ETH. You can [**bid here**](https://zora.co/chaim/3172). \n\n[NFT](ethereum://0xabEFBc9fD2F806065b4f3C237d4b59D9A97Bcac7/3172)\n\n# THE COLLECTIBLES\n\nThere are 9 collectible NFTs ‚Äî one for each song on the album. \n\n### **Tracks no. 1 thru 6 ‚Äî *Form, Tear, Sand, Red Balloons, Crazy, Island***\n\nThe collectibles for the 6 finished songs can be [viewed and collected here](https://rarible.com/chaim). Each NFT is an edition of 5, priced at 0.1 ETH. \n\nhttps://rarible.com/token/0xd07dc4262bcdbf85190c01c996b4c06a461d2430:572882:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details\n\nhttps://rarible.com/token/0xd07dc4262bcdbf85190c01c996b4c06a461d2430:572863:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details\n\nhttps://rarible.com/token/0xd07dc4262bcdbf85190c01c996b4c06a461d2430:572834:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details\n\nhttps://rarible.com/token/0xd07dc4262bcdbf85190c01c996b4c06a461d2430:572824:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details\n\nhttps://rarible.com/token/0xd07dc4262bcdbf85190c01c996b4c06a461d2430:572812:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details\n\nhttps://rarible.com/token/0xd07dc4262bcdbf85190c01c996b4c06a461d2430:572803:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details\n\nThe 3 unfinished songs each have their own mechanics in place to experiment with 3 different forms of collective creation‚Ä¶\n\n### **Track no. 7 ‚Äî *Flavors*** + the *Flavors Feature Contest*\n\n[NFT](ethereum://0x60f80121c31a0d46b5279700f9df786054aa5ee5/1012987)\n\n*Flavors* is written by Matt Parad + myself, and produced by Matt Parad. We started writing this song on my birthday. It was the first time Matt and I had ever worked together. \n\nThe song is nearly finished, but has an empty second verse that needs a feature. Hence, the ***Flavors Feature Contest***. Anyone who collects an NFT or purchases an album bundle copy receives one (1) entry into the contest. \n\nAfter your purchase and/or collection, you‚Äôll receive a private download of the album. Included will be an mp3 of Flavors with an open second verse. You can use that file to start writing your verse. You will also gain access to the Homemade Universe discord server, where you will be able to submit your version of Flavors. Submissions will close on June 20 2021. \n\nA winner will then be chosen to be the official feature of Flavors. The final version of the song with your verse on it will then be released as a 1/1 Catalog NFT and, eventually, on the Textures OF A Long Forgotten Assumption album release on streaming platforms. \n\n**The winner will also receive this 1/1 collectible NFT of Flavors, as well as 10% of the master‚Äôs future earnings (through NFT sales, streaming royalties etc).**\n\nhttps://rarible.com/token/0x60f80121c31a0d46b5279700f9df786054aa5ee5:1012987:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details\n\n### **Track no. 8 ‚Äî *Paint*** + the *Silent Auction*\n\n[NFT](ethereum://0x60f80121c31a0d46b5279700f9df786054aa5ee5/1012935)\n\nThe song *Paint* is still in a very early demo stage. In fact, I don‚Äôt yet have a chorus for it. I wrote the beginnings of this song with Danny Majic, and have always loved the first verse and pre-chorus. But there is still a ways to go on this song, and I am looking for 1 partner to join along for the ride. \n\nThis partner will be the ***creative director*** for the song *Paint* ‚Äî and this role can look many different ways. Perhaps you‚Äôre a musician and can help with the songwriting or production of the song, perhaps you‚Äôre visual artists and can help on the visual side. Perhaps you don‚Äôt consider yourself an artist whatsoever, but can help on the outreach and marketing side. Perhaps you just want to get a closer look into the makings of a song, and just want to take pictures of the process on your disposable camera. Whatever it may be! This creative director position is yours to fill however you choose, should you win it of course. \n\nNow, how do you win it?\n\nThe *Paint* collectible is a 1/1 NFT on Rarible, and is up for **Silent Auction**. \n\nYes, that‚Äôs correct. Silent Auction. \n\nTo win this auction, you must email me your bid. \n\nThat‚Äôs correct. Email me your bid at paintauctionbid@gmail.com. \n\nYour bid can be in ETH, it can be in USD, it can be in CAD, or DOGE or WRITE or any other currency on the planet. It can also be a non-currency bid! It can be a barter of some kind ‚Äî maybe a good or maybe a service. Anything! Get creative! \n\nThis is for the role of creative director on the song. So show me your creativity. And show me how much you want it. :)\n\nOnce the first bid is in, a 24-hour countdown will commence. I will announce updates on the Silent Auction in real-time on [twitter](https://twitter.com/matthewchaim). \n\n**The winner will be the official creative director for *Paint*, win this 1/1 collectible NFT, and receive 10% of the master‚Äôs future earnings (through NFT sales, streaming royalties etc).**\n\nhttps://rarible.com/token/0x60f80121c31a0d46b5279700f9df786054aa5ee5:1012935:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details\n\n### **Track no. 9 ‚Äî *Untitled*** + the *Untitled Creative Director DAO*\n\n[NFT](ethereum://0xd07dc4262bcdbf85190c01c996b4c06a461d2430/572927)\n\nGrab your [entry NFT into the *Untitled Creative Director DAO* here](https://rarible.com/token/0xd07dc4262bcdbf85190c01c996b4c06a461d2430:572927:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details).\n\n1 creative director is great. But what about 100? \n\nYes, that‚Äôs correct. 100 creative directors. \n\nThat is what I am in search of for this last song on the album, which does not yet even have a name. As you can see, we have our work cut out for ourselves. \n\nIn fact, I‚Äôm not even sure which demo on mine should be the 9th and final song on the project. There are a few options that I really love, but I need your help to decide on which one to pursue. That is where we will start our collective decision making. Here‚Äôs how it works:\n\nThe Untitled collectible is a **100 edition** NFT on [Rarible](https://rarible.com/token/0xd07dc4262bcdbf85190c01c996b4c06a461d2430:572927:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details), with each edition priced at **0.03 ETH**. I ask that you purchase a maximum of **1 edition per wallet**. \n\nThe Untitled collectible NFT will act as the access token into a gated set of channels on the Homemade Universe discord, where this community of 100 people will convene and begin the creative direction of the song. \n\n**Each edition represents 1 vote in the *Untitled Creative Director DAO* that will be formed to govern the completion of this final song of the album, as well as 0.1% of the master‚Äôs future earnings (through NFT sales, streaming royalties, etc). This means that 100 people will together own 10% of the song‚Äôs final master.**\n\nhttps://rarible.com/token/0xd07dc4262bcdbf85190c01c996b4c06a461d2430:572927:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details\n\n# THE COPIES\n\nThe final form this album is being released today is with **1000 album bundle copies**, [available for purchase on my online shop here](https://ko-fi.com/s/794a026bac). \n\nThis bundle comes with:\n1. the first 7 tracks off the album, including *Flavors* with the empty second verse\n2. 8 pieces of album artwork\n3. one (1) invitation to *Homemade Universe*\n4. one (1) entry into the *Flavors Feature Contest* (more info in the Collectibles section above\n\nAfter your purchase, you will receive an access card into the Homemade Universe discord ‚Äî which will give you access to the private set of channels available to members. \n\nThe album bundle will be available for up to two weeks or up to 1000 copies, whichever comes first. \n\n**You can [purchase an album bundle copy here](https://ko-fi.com/s/794a026bac).**\n\n![](https://images.mirror-media.xyz/publication-images/f29b829a-3e2e-4aba-aee9-2ab41f399355.jpg?height=3000&width=3000)\n\n# A Super Short Recap \n\nMy album *Textures Of A Long Forgotten Assumption* drops today, but not on streaming platforms. \n\nThe full album is made up of 9 songs. 6 of them are done. 3 of them aren‚Äôt. I need your help to finish the project. \n\nYou can participate in the drop through 3 form factors:\n1. The Canon ‚Üí 4 one-of-one Catalog song NFTs + 1 one-of-one Zora music video NFT\n2. The Collectibles ‚Üí 9 vinyl NFTs available on Rarible, each with their own mechanics baked in\n3. The Copies ‚Üí 1000 album bundle copies available on my online shop\n\nAll of these give you access to:\n\n1. a private download of the album‚Äôs songs and artwork\n2. one (1) invitation into the *Homemade Universe* discord server ‚Äî my private online community\n3. one (1) entry into the *Flavors Feature Contest*. (more info on this in the *Collectibles* section)\n\n# A Final Thought \n\nIn building this release out, I realized I missed one more word in my cute little alliteration. \n\nThe full phrase should go ‚Üí Canon, Collectibles, Copies, and *Community*. \n\nThis project in some ways only *begins* today, in that it is the first page in our story of exploring collective creation together. For the final 3 songs, we will begin a new journey of seeing what it is like for a community to create together in 3 very different ways ‚Äî one as a contest, one as a 1-to-1 relationship, and 1 as a DAO making decisions together. It is also the beginning of exploring the possibilities around sharing in the equity of our co-creations in this way. \n\nThe other thing you may notice in the splits delineated in the *Canon* NFTs above, is my private community Homemade Universe is receiving 5% of all auction revenues. Those funds will go into a shared treasury controlled by the community, which we will use for future co-creative projects together. \n\nI‚Äôm incredibly excited to go on this new journey with you. And learn what it means to bring together like-minded individuals around my art, and create real value together. \n\nThis is just the beginning. \n\nThanks for being here. üåª", "timestamp": 1621604229, "digest": "9EAsxtkQD6hIQJLDID5w8Jn6o_m9Bw4XnDdTwOVHttA", "contributor": "0x5090c4Fead5Be112b643BC75d61bF42339675448"}
{"id": "qEXgmxlKr8rK_M0hxHhHnkAtX-K4HhhBAYc4ikAygNY", "title": "Introducing the Komorebi Collective \n", "body": "Investing in female and non-binary crypto founders\n![](https://images.mirror-media.xyz/publication-images/c48491ad-abe2-491c-b514-56df79977501.png?height=500&width=1500)\n\n\n\nToday, she256, Women in Blockchain, Kinjal Shah and allies are excited to announce [Komorebi Collective](https://www.syndicateprotocol.org/syndicate/komorebi_collective), a fund focused on investing in exceptional female and non-binary crypto founders.\n \nFundamentally, we believe that blockchain will shape our future financial and governance structures, and it‚Äôs crucial that those building these systems represent the global, diverse population that the industry aims to serve. \n\n*Komorebi* is a poetic, almost untranslatable, Japanese expression that describes sunlight filtering through trees. These rays of light illuminate the forest undergrowth which is otherwise difficult to see. Inspired by this sentiment, the Komorebi Collective aims to illuminate and elevate a group of otherwise underestimated visionary founders building in crypto. \n\n## Our Collective \nWe‚Äôve been participating in the crypto ecosystem as builders, investors and community shepherds. We‚Äôre proud to take the next step in ensuring a more diverse future of crypto builders and beneficiaries around the world.\n\nOur core team consists of members from [she256](http://she256.org/), a 501c3 nonprofit dedicated to increasing diversity and breaking down barriers to entry in the blockchain space, as well as [Women in Blockchain](https://blockchaingirls.org/), an organization focused on increasing diversity through education and community building. \n\nStructurally, Komorebi runs as a decentralized autonomous organization (DAO) on the [Syndicate Protocol](https://twitter.com/SyndicateDAO).\n\n## Why Now?\nInvesting in women and non-binary folks isn‚Äôt just a necessity, **it‚Äôs financially sound**. Teams with at least one female founder [exit faster](https://files.pitchbook.com/website/files/pdf/PitchBook_All_Raise_2019_All_In_Women_in_the_VC_Ecosystem.pdf) (6.9 years compared to 7.4 years for all-male teams). According to [First Round](http://10years.firstround.com/), companies with a female founder performed 63% better than their investments with all-male founding teams. \n\nAnd yet, last year, **women-led startups received only [2.3%](https://news.crunchbase.com/news/global-vc-funding-to-female-founders/) of venture funding**. In addition, [65%](https://allraise-data-dashboard.s3-us-west-2.amazonaws.com/center/html/index.html) of venture funds still have NO female checkwriters. These two stats are very much related; female VCs are [2x](https://www.kauffmanfellows.org/journal_posts/women-vcs-invest-in-up-to-2x-more-female-founders) more likely to fund a female founder than male VCs.\n\nKomorebi plans on addressing both of these issues head on. We refuse to let broader tech and venture‚Äôs shortcomings trickle into crypto. With crypto growing faster than ever, a recent [research survey](https://blockchaingirls.org/global-research-report) of women around the world by Women in Blockchain highlighted that 36% of respondents were interested in the underlying technology, 14% saw crypto as a means to improving their financial independence and a resounding 80% prefer to be paid in crypto. We now have the unique opportunity to set the course of the space ‚Äî we aim to redefine funding and founding in web3.\n\n## Meet the members\n\n### Core:\n\n- Eva Wu, she256, Mechanism Capital\n- Kristie Huang, she256, Pantera Capital\n- Medha Kothari, she256, Celo\n- Manasi Vora, Women in Blockchain, Skynet\n- Kinjal Shah, Blockchain Capital\n\n### Members:\n\n- Kleiner Perkins\n- Mechanism Capital\n- Dragonfly Capital \n- IDEO CoLab Ventures\n- Stacks Accelerator\n- Dovey Wan, Founding Partner at Primitive Ventures \n- Justine Humenansky, Investor at Playground Global\n- Maria Shen, Investor at Electric Capital\n- Vanessa Slavich, Partner at Celo Foundation\n- Tess Rinearson, VP Engineering at Interchain GmbH, Tendermint\n- Isabelle Wei, Engineer at Valora\n- Mimi Idada, Head of Open Web Collective, Mentorship Lead at she256\n- Joyce Yang, Investor at Globalcoin Ventures\n- Leigh Cuen, Journalist\n- Alexis Gauba, Co-founder of Opyn, Co-Founder of she256\n- Amy Jung, Head of Community at MakerDAO\n- Maggie Love, Founder of W3bcloud, Founder of SheFi \n- Andrea Lo, Sr Director of Investments at Stellar Development Foundation \n- Fulvia Morales, Product at 0x, Investor at FreeCompany\n- Stani Kulechov, Founder of Aave\n- Robert Leshner, Co-founder of Compound\n- Ian Lee, MD at IDEO CoLab Ventures, Co-founder of Syndicate\n- Jesse Pollak, Head of Engineering for Consumer Products at Coinbase\n- Daryl Lau, Principal at Mechanism Capital\n- Vivek Singh, Co-founder of Gitcoin\n- Hamdi Allam, Engineer at Twitter, Co-founder of FourthState\n- Marc Weinstein, Portfolio Development at Mechanism Capital\n- Connor McEwen, Engineering Lead at Celo Labs\n- Benjamin Simon, Research at Mechanism Capital\n- David Vorick, Founder of Skynet Labs\n- Jesse Walden, Founder of Variant Fund\n\n## Starting a Crypto Company?\nIf you‚Äôre interested in learning more, please reach out!. You can find us here: [email](mailto:komorebi@syndicateprotocol.org) | [twitter](https://twitter.com/KomorebiFund) | [website](https://www.syndicateprotocol.org/syndicate/komorebi_collective) \n\n*Special thanks to Ian Lee, Will Papper, the rest of the Syndicate Protocol team, as well as she256 and Women in Blockchain for providing operational support.*", "timestamp": 1621607338, "digest": "yaZDFK3VP5dsbzaeAaSe3aMCtIxilvDTK0NYHO4ossU", "contributor": "0x16DFe71Fe5269a794d255017326F9A5dB8591B22"}
{"id": "u4N0eysHjTssrSu9DFvYqf-2ifsGFqjvaQFWsJYAYyo", "title": "Patrick Entry", "body": "derp", "timestamp": 1621610260, "digest": "fXktXZKf3G0fJgg-nXNIeD1Is-PxB3bH8hYn5BlK4ec", "contributor": "0x942cBEa64876Ff0b2e23c0712B37Dc0091804e9c"}
{"id": "Ks-SuAvPcE05ftIWOswYU5IiDP9XQAF8PwiMTVN2snI", "title": "Textures Of A Long Forgotten Assumption ‚Äî LIVE NOW üî¥", "body": "### *Shortcuts*\n\n1. The canonical [1/1 Catalog NFTs](https://beta.catalog.works/chaim) are up for auction *below*\n2. The 9 collectible vinyl NFTs are [now available on Rarible](https://rarible.com/chaim) \n3. The 1000 album bundle copies are [available for purchase here](https://ko-fi.com/s/794a026bac) \n4. The official music video for *Form* is [up for auction on Zora](https://zora.co/chaim/3172)\n\n‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî \n\nWelcome to the official release of ***Textures Of A Long Forgotten Assumption*** ‚Äî my third album. \n\nThis 9-song body of work explores the fundamental beliefs we all have and don't dare question. What happens when we do? \n\nThe release of this project aims to rip open some of those deeply held beliefs we have around music ‚Äî what music is, how we value it, and how it‚Äôs ‚Äúsupposed to be‚Äù distributed. \n\nThis release is broken down into 3 sections: **The Canon, The Collectibles, and The Copies**. *To learn more about my thoughts behind this release mix, [read my previous essay](https://chaim.mirror.xyz/0SRGluR6sYweDWV0qmgF6V1wsN0BvEKsvCVOZCFX7yU).* \n\n### Here‚Äôs what‚Äôs happening:\n\n- There are 5 one-of-one *canon*ical NFTs on auction **below**\n- There are 9 NFT *collectibles* now [**available on Rarible**](https://rarible.com/chaim), which are walked through in detail below \n- There are 1000 album bundle *copies* [**now available on my online shop**](https://ko-fi.com/s/794a026bac), also walked through below \n\n### All collectors of any of the above will receive: \n\n- a private download of the *Textures Of A Long Forgotten Assumptions* album's songs and artwork\n- one (1) invitation into the *Homemade Universe* discord server ‚Äî my private online community. \n- one (1) entry into the *Flavors Feature Contest*. More on this below. \n\n## The full *Textures Of A Long Forgotten Assumption* tracklist is:\n1. Form\n2. Tear\n3. Sand\n4. Red Balloons\n5. Crazy\n6. Island\n7. Flavors (unfinished)\n8. Paint (unfinished)\n9. Untitled (unfinished)\n\nAs you can see, **three of the nine songs are unfinished**. I need your help to finish them, and you can see how in the *Collectibles* section below. \n\nLet‚Äôs begin...\n\n![](https://images.mirror-media.xyz/publication-images/406d2f77-5164-4980-8fc6-e991ed8bfdc9.jpg?height=3000&width=3000)\n\n\n# THE CANON\n\nOn auction are 4 one-of-one [Catalog NFTs](https://beta.catalog.works/chaim) for tracks 3 thru 6 ‚Äî *Sand*, *Red Balloons*, *Crazy* and *Island*. There is also a one-of-one Zora NFT for the official *Form* music video, auctioning off on Zora. \n\nYou can see who the recipients are for each of the 4 Catalog NFTs being auctioned below. These are the collaborators (writers, producers, engineers) I created this music with. \n\n## Track No. 3 ‚Äî Sand\n\n*Sand* is written by Danny Majic + myself, and produced by Danny Majic.\n\nThis was the first song Danny and I ever wrote together, the very day we met each other. This was also the very first song I wrote after a 10-day cross-country solo drive from Montreal, Canada to Los Angeles, California. \n\n[Token #3166](auction://0xabEFBc9fD2F806065b4f3C237d4b59D9A97Bcac7?network=mainnet&tokenId=3166)\n\n## Track No. 4 ‚Äî Red Balloons\n\n*Red Balloons* is written by Hayley Gene Penner, Jason Yik Nam Wu + myself, and produced by Rabitt.\n\nThis is the first song I've ever released with a co-written top-line. I've always found it difficult to write lyrics and melody with others, but Hayley is a great friend and we truly found a shared energy on this one. And Rabitt always brings the goods. \n\n[Token #3167](auction://0xabEFBc9fD2F806065b4f3C237d4b59D9A97Bcac7?network=mainnet&tokenId=3167)\n\n## Track No. 5 ‚Äî Crazy\n\n*Crazy* is written by Danny Majic + myself, and produced by Danny Majic.\n\nWe wrote this song together at a songwriting camp in Nashville, Tennessee. It was the first ever *Really Fun Camp* organized by Rabitt. \n\n[Token #3168](auction://0xabEFBc9fD2F806065b4f3C237d4b59D9A97Bcac7?network=mainnet&tokenId=3168)\n\n## Track No. 6 ‚Äî Island\n\n*Island* is written by Jason Yik Nam Wu + myself, and produced by Rabitt.\n\nWe wrote this song together in Jason's studio in Silverlake, Los Angeles. Attached to said studio was the very house we were both living in at the time. This was the last song we wrote together, before I left for Montreal when the pandemic began. A version of the song was first released on streaming platforms in May 2020, on a charity album raising money for MusiCares' Covid Relief Fund. \n\n[Token #3169](auction://0xabEFBc9fD2F806065b4f3C237d4b59D9A97Bcac7?network=mainnet&tokenId=3169)\n\nAs you can see in the auctions above above, **5% of funds received are going towards my private community *Homemade Universe*‚Äôs shared treasury**. These funds will be used in future co-creative projects together. Since all collectors + purchasers gain access to *Homemade Universe*, 5% of this project‚Äôs proceeds are funnelling into a community that you are co-creator and co-owner of. \n\n## Form ‚Äî The Official Music Video \n\nThe official music video for \"Form\" is [**now up for auction on Zora**](https://zora.co/chaim/3172), filmed + edited by myself while stuck in a quarantine hotel in Montreal in May 2020. ü•Ω\n\n*Form* is written by Jason Yik Nam Wu + myself, and produced by Rabitt.\n\nThe reserve bid is 0.5 ETH. You can [**bid here**](https://zora.co/chaim/3172). \n\n[NFT](ethereum://0xabEFBc9fD2F806065b4f3C237d4b59D9A97Bcac7/3172)\n\n# THE COLLECTIBLES\n\nThere are 9 collectible NFTs ‚Äî one for each song on the album. \n\n### **Tracks no. 1 thru 6 ‚Äî *Form, Tear, Sand, Red Balloons, Crazy, Island***\n\nThe collectibles for the 6 finished songs can be [viewed and collected here](https://rarible.com/chaim). Each NFT is an edition of 5, priced at 0.1 ETH. \n\nhttps://rarible.com/token/0xd07dc4262bcdbf85190c01c996b4c06a461d2430:572882:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details\n\nhttps://rarible.com/token/0xd07dc4262bcdbf85190c01c996b4c06a461d2430:572863:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details\n\nhttps://rarible.com/token/0xd07dc4262bcdbf85190c01c996b4c06a461d2430:572834:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details\n\nhttps://rarible.com/token/0xd07dc4262bcdbf85190c01c996b4c06a461d2430:572824:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details\n\nhttps://rarible.com/token/0xd07dc4262bcdbf85190c01c996b4c06a461d2430:572812:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details\n\nhttps://rarible.com/token/0xd07dc4262bcdbf85190c01c996b4c06a461d2430:572803:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details\n\nThe 3 unfinished songs each have their own mechanics in place to experiment with 3 different forms of collective creation‚Ä¶\n\n### **Track no. 7 ‚Äî *Flavors*** + the *Flavors Feature Contest*\n\n[NFT](ethereum://0x60f80121c31a0d46b5279700f9df786054aa5ee5/1012987)\n\n*Flavors* is written by Matt Parad + myself, and produced by Matt Parad. We started writing this song on my birthday. It was the first time Matt and I had ever worked together. \n\nThe song is nearly finished, but has an empty second verse that needs a feature. Hence, the ***Flavors Feature Contest***. Anyone who collects an NFT or purchases an album bundle copy receives one (1) entry into the contest. \n\nAfter your purchase and/or collection, you‚Äôll receive a private download of the album. Included will be an mp3 of Flavors with an open second verse. You can use that file to start writing your verse. You will also gain access to the Homemade Universe discord server, where you will be able to submit your version of Flavors. Submissions will close on June 20 2021. \n\nA winner will then be chosen to be the official feature of Flavors. The final version of the song with your verse on it will then be released as a 1/1 Catalog NFT and, eventually, on the Textures OF A Long Forgotten Assumption album release on streaming platforms. \n\n**The winner will also receive this 1/1 collectible NFT of Flavors, as well as 10% of the master‚Äôs future earnings (through NFT sales, streaming royalties etc).**\n\nhttps://rarible.com/token/0x60f80121c31a0d46b5279700f9df786054aa5ee5:1012987:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details\n\n### **Track no. 8 ‚Äî *Paint*** + the *Silent Auction*\n\n[NFT](ethereum://0x60f80121c31a0d46b5279700f9df786054aa5ee5/1012935)\n\nThe song *Paint* is still in a very early demo stage. In fact, I don‚Äôt yet have a chorus for it. I wrote the beginnings of this song with Danny Majic, and have always loved the first verse and pre-chorus. But there is still a ways to go on this song, and I am looking for 1 partner to join along for the ride. \n\nThis partner will be the ***creative director*** for the song *Paint* ‚Äî and this role can look many different ways. Perhaps you‚Äôre a musician and can help with the songwriting or production of the song, perhaps you‚Äôre visual artists and can help on the visual side. Perhaps you don‚Äôt consider yourself an artist whatsoever, but can help on the outreach and marketing side. Perhaps you just want to get a closer look into the makings of a song, and just want to take pictures of the process on your disposable camera. Whatever it may be! This creative director position is yours to fill however you choose, should you win it of course. \n\nNow, how do you win it?\n\nThe *Paint* collectible is a 1/1 NFT on Rarible, and is up for **Silent Auction**. \n\nYes, that‚Äôs correct. Silent Auction. \n\nTo win this auction, you must email me your bid. \n\nThat‚Äôs correct. Email me your bid at paintauctionbid@gmail.com. \n\nYour bid can be in ETH, it can be in USD, it can be in CAD, or DOGE or WRITE or any other currency on the planet. It can also be a non-currency bid! It can be a barter of some kind ‚Äî maybe a good or maybe a service. Anything! Get creative! \n\nThis is for the role of creative director on the song. So show me your creativity. And show me how much you want it. :)\n\nOnce the first bid is in, a 24-hour countdown will commence. I will announce updates on the Silent Auction in real-time on [twitter](https://twitter.com/matthewchaim). \n\n**The winner will be the official creative director for *Paint*, win this 1/1 collectible NFT, and receive 10% of the master‚Äôs future earnings (through NFT sales, streaming royalties etc).**\n\nhttps://rarible.com/token/0x60f80121c31a0d46b5279700f9df786054aa5ee5:1012935:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details\n\n### **Track no. 9 ‚Äî *Untitled*** + the *Untitled Creative Director DAO*\n\n[NFT](ethereum://0xd07dc4262bcdbf85190c01c996b4c06a461d2430/572927)\n\nGrab your [**entry NFT into the *Untitled Creative Director DAO* here**](https://rarible.com/token/0xd07dc4262bcdbf85190c01c996b4c06a461d2430:572927:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details).\n\n1 creative director is great. But what about 100? \n\nYes, that‚Äôs correct. 100 creative directors. \n\nThat is what I am in search of for this last song on the album, which does not yet even have a name. As you can see, we have our work cut out for ourselves. \n\nIn fact, I‚Äôm not even sure which demo on mine should be the 9th and final song on the project. There are a few options that I really love, but I need your help to decide on which one to pursue. That is where we will start our collective decision making. Here‚Äôs how it works:\n\nThe Untitled collectible is a **100 edition** NFT on [Rarible](https://rarible.com/token/0xd07dc4262bcdbf85190c01c996b4c06a461d2430:572927:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details), with each edition priced at **0.03 ETH**. I ask that you purchase a maximum of **1 edition per wallet**. \n\nThe Untitled collectible NFT will act as the access token into a gated set of channels on the Homemade Universe discord, where this community of 100 people will convene and begin the creative direction of the song. \n\n**Each edition represents 1 vote in the *Untitled Creative Director DAO* that will be formed to govern the completion of this final song of the album, as well as 0.1% of the master‚Äôs future earnings (through NFT sales, streaming royalties, etc). This means that 100 people will together own 10% of the song‚Äôs final master.**\n\nhttps://rarible.com/token/0xd07dc4262bcdbf85190c01c996b4c06a461d2430:572927:0x5090c4fead5be112b643bc75d61bf42339675448?tab=details\n\n# THE COPIES\n\nThe final form this album is being released today is with **1000 album bundle copies**, [available for purchase on my online shop here](https://ko-fi.com/s/794a026bac). \n\nThis bundle comes with:\n1. the first 7 tracks off the album, including *Flavors* with the empty second verse\n2. 8 pieces of album artwork\n3. one (1) invitation to *Homemade Universe*\n4. one (1) entry into the *Flavors Feature Contest* (more info in the Collectibles section above\n\nAfter your purchase, you will receive an access card into the Homemade Universe discord ‚Äî which will give you access to the private set of channels available to members. \n\nThe album bundle will be available for up to two weeks or up to 1000 copies, whichever comes first. \n\n**You can [purchase an album bundle copy here](https://ko-fi.com/s/794a026bac).**\n\n![](https://images.mirror-media.xyz/publication-images/f29b829a-3e2e-4aba-aee9-2ab41f399355.jpg?height=3000&width=3000)\n\n# A Super Short Recap \n\nMy album *Textures Of A Long Forgotten Assumption* drops today, but not on streaming platforms. \n\nThe full album is made up of 9 songs. 6 of them are done. 3 of them aren‚Äôt. I need your help to finish the project. \n\nYou can participate in the drop through 3 form factors:\n1. The Canon ‚Üí 4 one-of-one Catalog song NFTs + 1 one-of-one Zora music video NFT\n2. The Collectibles ‚Üí 9 vinyl NFTs available on Rarible, each with their own mechanics baked in\n3. The Copies ‚Üí 1000 album bundle copies available on my online shop\n\nAll of these give you access to:\n\n1. a private download of the album‚Äôs songs and artwork\n2. one (1) invitation into the *Homemade Universe* discord server ‚Äî my private online community\n3. one (1) entry into the *Flavors Feature Contest*. (more info on this in the *Collectibles* section)\n\n# A Final Thought \n\nIn building this release out, I realized I missed one more word in my cute little alliteration. \n\nThe full phrase should go ‚Üí Canon, Collectibles, Copies, and *Community*. \n\nThis project in some ways only *begins* today, in that it is the first page in our story of exploring collective creation together. For the final 3 songs, we will begin a new journey of seeing what it is like for a community to create together in 3 very different ways ‚Äî one as a contest, one as a 1-to-1 relationship, and 1 as a DAO making decisions together. It is also the beginning of exploring the possibilities around sharing in the equity of our co-creations in this way. \n\nThe other thing you may notice in the splits delineated in the *Canon* NFTs above, is my private community Homemade Universe is receiving 5% of all auction revenues. Those funds will go into a shared treasury controlled by the community, which we will use for future co-creative projects together. \n\nI‚Äôm incredibly excited to go on this new journey with you. And learn what it means to bring together like-minded individuals around my art, and create real value together. \n\nThis is just the beginning. \n\nThanks for being here. üåª", "timestamp": 1621611455, "digest": "9EAsxtkQD6hIQJLDID5w8Jn6o_m9Bw4XnDdTwOVHttA", "contributor": "0x5090c4Fead5Be112b643BC75d61bF42339675448"}
{"id": "jgKmlK6EAdLYbnk8XyZeREelrFwHCstRZRUx6lZXJM8", "title": "Hello Web3", "body": "![](https://images.mirror-media.xyz/publication-images/b4cee1ed-97a9-48d9-aa6b-18132865af96.png?height=1140&width=1900)\n", "timestamp": 1621612059, "digest": "nRiq5uNmxgywhzSk4WL_1geDSEf7l0owtogqG4nU3Ts", "contributor": "0xcde3725B25D6d9bC78CF0941cC15Fd9710c764b9"}
{"id": "P_9TJPj9Gt1I87ejF_yqVkfdPMrfnktstpJOBsHF64U", "title": "Hello Web3", "body": "![](https://images.mirror-media.xyz/publication-images/b4cee1ed-97a9-48d9-aa6b-18132865af96.png?height=1140&width=1900)\n\n\n\n", "timestamp": 1621612038, "digest": "nRiq5uNmxgywhzSk4WL_1geDSEf7l0owtogqG4nU3Ts", "contributor": "0xcde3725B25D6d9bC78CF0941cC15Fd9710c764b9"}
{"id": "cDL6eAfYllW6FYS-rNJNOHkIDaVronh8i-edc-jce1k", "title": "Hello Web3", "body": "![](https://images.mirror-media.xyz/publication-images/94d47458-feb2-4c55-be98-a69114fdee7b.png?height=1140&width=1900)\n\n\n", "timestamp": 1621612382, "digest": "nRiq5uNmxgywhzSk4WL_1geDSEf7l0owtogqG4nU3Ts", "contributor": "0xcde3725B25D6d9bC78CF0941cC15Fd9710c764b9"}
{"id": "bSpurZJ1K70eK-6NVqhOQ2Gm_jPgu48awKR39SYxCZ0", "title": "PartyDAO", "body": "PartyDAO has two primary mandates.\n\n1. Ship PartyBid: a product / standard for creating popup DAOs that can bid on NFTs\n2. Build PartyDAO itself into a long-lasting organization that can fund its own continued existence.\n\nPartyDAO is different from many DAOs that have come before it. To date, DAOs have mostly been synonymous with a treasury of funds + group voting on where to send those funds. PartyDAO aims to be something else: **we are a fully decentralized organization that actually ships products**.\n\nAlready, PartyDAO has assembled a group of members with strong capabilities in design, engineering, smart contract development, and writing. As we build this first product, we will use these skills to ship a product at a quality level typically only seen at top-tier startups. In doing so, we will begin to expand on the idea of what a DAO is capable of.\n\nOver the next several weeks, we will also progress towards the much larger opportunity of building a long-lasting organization. We‚Äôll establish the PartyDAO identity and continue to build up a list of members with skills we can call on. Though we are building things together, we are not a company. We are a group of autonomous individuals that can coordinate around shared projects that we all own a part of.\n\n---\n\nIn the immediate, we have 2 primary work streams to pursue in parallel.\n\nFirst, we have begun building PartyBid V1. In the past week, we've cemented our V1 spec and selected a team responsible for project management, design, and development. That team consists of the following members, and development is now underway.\n\n- Project Lead: [John Palmer](https://twitter.com/john_c_palmer)\n- Lead solidity developer: [Anna Carroll](https://twitter.com/annascarroll)\n- Designer: [Callil Capuozzo](https://twitter.com/_callil)\n- Web developer: [Anish Agnihotri](https://twitter.com/_anishagnihotri)\n- Solidity reviewers: [Steve Klabenoff](https://twitter.com/steveklbnf), [Graeme Boy](https://twitter.com/strangechances), and [Arpit Agarwal](https://twitter.com/atvanguard)\n\nSecond, we have slowly begun building PartyDAO itself. While only a few individuals are building our first product PartyBid V1, every member is a part of establishing the DAO as an organization by sharing what we're up to and inviting new members to join.\n\nAs far as this goes, we've made initial progress by creating our publication on Mirror and publishing this first post. Additionally, we've elected our official mascot, Kazoo. Over the coming weeks, we'll have a lot more to share.\n\n![](https://images.mirror-media.xyz/publication-images/25356535-e48f-47ee-a221-c61993d17056.jpeg?height=3000&width=3000)\n\n---\n\nFinally, it's important to note the energy of PartyDAO. PartyDAO is a chaotic group of talented individuals whose goal is to have a good time building things. We are fundamentally opposed to the idea of work without play. Therefore, our number one rule is simple: **Have fun**.", "timestamp": 1621614190, "digest": "xte55cT3ESlQRP62KYxupRbha7A1O6MMHhKMIzfmLyg", "contributor": "0xB0623C91c65621df716aB8aFE5f66656B21A9108"}
{"id": "ri9mQ5VB-esPMX7Q0645YM1HpKExm2h6BbYaZUYxpIo", "title": "PartyDAO", "body": "PartyDAO has two primary mandates.\n\n1. Ship PartyBid: a product / standard for creating popup DAOs that can bid on NFTs\n2. Build PartyDAO itself into a long-lasting organization that can fund its own continued existence.\n\nPartyDAO is different from many DAOs that have come before it. To date, DAOs have mostly been synonymous with a treasury of funds + group voting on where to send those funds. PartyDAO aims to be something else: **we are a fully decentralized organization that actually ships products**.\n\nAlready, PartyDAO has assembled a group of members with strong capabilities in design, engineering, smart contract development, and writing. As we build this first product, we will use these skills to ship a product at a quality level typically only seen at top-tier startups. In doing so, we will begin to expand on the idea of what a DAO is capable of.\n\nOver the next several weeks, we will also progress towards the much larger opportunity of building a long-lasting organization. We‚Äôll establish the PartyDAO identity and continue to build up a list of members with skills we can call on. Though we are building things together, we are not a company. We are a group of autonomous individuals that can coordinate around shared projects that we all own a part of.\n\n---\n\nIn the immediate, we have 2 primary work streams to pursue in parallel.\n\nFirst, we have begun building PartyBid V1. In the past week, we've cemented our V1 spec and selected a team responsible for project management, design, and development. That team consists of the following members, and development is now underway.\n\n- Project Lead: [John Palmer](https://twitter.com/john_c_palmer)\n- Lead solidity developer: [Anna Carroll](https://twitter.com/annascarroll)\n- Designer: [Callil Capuozzo](https://twitter.com/_callil)\n- Web developer: [Anish Agnihotri](https://twitter.com/_anishagnihotri)\n- Solidity reviewers: [Steve Klabenoff](https://twitter.com/steveklbnf), [Graeme Boy](https://twitter.com/strangechances), and [Arpit Agarwal](https://twitter.com/atvanguard)\n\nSecond, we have slowly begun building PartyDAO itself. While only a few individuals are building PartyBid V1, every member is a part of establishing the DAO as an organization by sharing what we're up to and inviting new members to join.\n\nAs far as this goes, we've made initial progress by creating our publication on Mirror and publishing this first post. Additionally, we've elected our official mascot, Kazoo.\n\n![](https://images.mirror-media.xyz/publication-images/25356535-e48f-47ee-a221-c61993d17056.jpeg?height=3000&width=3000)\n\n---\n\nOver the coming weeks, we'll have a lot more to share here. Even though it's early, what's shaping up in the PartyDAO Discord already resembles much more established crypto projects.", "timestamp": 1621615743, "digest": "xte55cT3ESlQRP62KYxupRbha7A1O6MMHhKMIzfmLyg", "contributor": "0xB0623C91c65621df716aB8aFE5f66656B21A9108"}
{"id": "xvXCqLRpO8vQ8k7etaxIi1COP5C-9uyZV8YDH_BU79Q", "title": "Just a test", "body": "To see how it is looking!\n\nSaving as a draft.", "timestamp": 1621618006, "digest": "ZdkVBFMWb37XCKFOXgxQQQz85Cnjy-wWBv5JelHrlvU", "contributor": "0x841fF85B6873d7bfB712C8f7A347C774355b6EC3"}
{"id": "AwHXSJB5Z5xItBZcjJ7DcmmN122OlqQSf7YXc1qeMHs", "title": "Just a test", "body": "To see how it is looking!\n\nSaving as a draft.\n\nAnother!", "timestamp": 1621618014, "digest": "ZdkVBFMWb37XCKFOXgxQQQz85Cnjy-wWBv5JelHrlvU", "contributor": "0x841fF85B6873d7bfB712C8f7A347C774355b6EC3"}
{"id": "bihlt94QsPuGILiRFGCbLQmyis3QPhCfDTFSDDQGOVs", "title": "Just a test", "body": "To see how it is looking!\n\nSaving as a draft.\n\nAnother!\n\nExample!", "timestamp": 1621618076, "digest": "ZdkVBFMWb37XCKFOXgxQQQz85Cnjy-wWBv5JelHrlvU", "contributor": "0x841fF85B6873d7bfB712C8f7A347C774355b6EC3"}
{"id": "CLanq-5X3gAtin_iS1MoJmFT2yjG5cL9jlp-_XfqjSI", "title": "Eco Friendly Ethereum 2.0 and why it‚Äôs happening with or without anti NFT Pressure", "body": "[![Sillytuna](https://miro.medium.com/fit/c/56/56/2\\*qaEuE8MQZrXBn3mcAjc2cQ.png)](https://sillytuna.medium.com/?source=post_page-----f1b1c363f52f--------------------------------)\n\nI‚Äôve been asked to provide proof to show that Ethereum isn‚Äôt going to remain a proof of work chain so here is a little background and a reading list. A common misconception seems to be that Ethereum benefits from proof of work and that this is some meaningless calculation that destroys the environment.\n\nFirstly, let‚Äôs start engaging our brains and stop being reactionary. And secondly, the burden of proof is on the accuser. It‚Äôs inexcusable to keep pushing false narratives then blaming the other party for not providing proof that typing ‚Äúgoogle ethereum 2.0‚Äù provides.\n\nQ: Why would a community deliberately create a platform that consumes energy for no purpose?\n\nA: They wouldn‚Äôt.\n\nProof of work is part of a consensus system critical to operating highly decentralised platforms. In the early days of Bitcoin there was no viable alternative. Over the last ten years alternatives have been and are being developed but they aren‚Äôt binary. There is no single method and everything has trade offs that need time and expertise to identify and improve upon.\n\n**Consensus systems and related components are the bleeding edge of computer science and involve game theory, cryptography and extremely complex maths. It actually is rocket science.**\n\nI cannot make it easy to understand because it‚Äôs beyond all but the very smartest minds. Bitcoin‚Äôs consensus is the simplest and is understandable though so it‚Äôs [the best place to start](https://bitcoin.org/bitcoin.pdf).\n\nProof of work‚Äôs energy use is out of control. I‚Äôm in no way a proponent of it. No one expected it to get like this and no one should be defending it. However, there is no magic bullet, it takes time to move from one to another. Those projects which started as alternatives which do not affect the environment have massive trade offs, some of which are the very antithesis of what blockchains are about.\n\nThat said, Ethereum [may](http://sterlingcrispin.blogspot.com/2021/02/crypto-art-sky-is-not-falling.html) have approximately the same CO2 output as Youtube and NFTs are less than 3% of Ethereum‚Äôs use. One of those is an enormous company, the other is a community project striving for change. Who are you giving grief to?And artists of all people?\n\nNot using NFTs also wouldn‚Äôt make a difference because this is **not** how blockchains work as Memo et al have repeatedly been told. Misunderstands in complex areas happen but when you repeatedly double down on your incorrect facts then it‚Äôs no longer a misunderstanding but a deliberate ploy to deceive for personal gain. **This is exactly how populist politicians work and it‚Äôs shameful that artists are 1) acting like this and 2) following populist leaders.**\n\nMemo et al are wrong because a per transaction metric is *only* valid when looking at efficiency ‚Äî PoW is deeply inefficient. Putting a little economics aside, adding more transactions makes no difference because ethereum can‚Äôt process any additional transactions. It‚Äôs *full* and has been for a long time.\n\n**If Ethereum is full, how can it work?**\n\nIf people pay more, their transaction is put ahead of others since there is a marketplace for transactions. This is why adding an NFT or not makes no difference ‚Äî it‚Äôs already full, you‚Äôre just replacing one transaction with another. Think of it like taxi cabs in New York where there are only ever a fixed number of cabs, always in demand, but a rising number of customers. During busy periods waits get longer and prices go up.\n\nSee <https://txstreet.com/> for a brilliant live visualiser!\n\n**Why would Ethereum stick to Proof of Work?**\n\n*   Long term highly decentralised proof of stake systems don‚Äôt exist because they‚Äôre supremely difficult to make\n*   I have nothing else. Sorry.\n\n**Why would we move from Proof of Work (to a combination of systems)?**\n\n*   Transaction fees dramatically fall, from tens of dollars to cents or less\n*   Chain efficiency dramatically rises, so we can do many thousands of transactions instead of about 12 per second\n*   Transaction speed vastly improves and something called chain finality, a highly desirable trait, is possible\n*   Staking rewards instead of miner rewards (explained below)\n*   It‚Äôs bad for the environment and not surprisingly many people on an open platform care a lot about that\n\n**Is Ethereum serious about moving?**\n\nFor all the reasons above, very emphatically yes!\n\nI gave the only reason for keeping proof of work but ethereum committed to changing to proof of stake at least 4 years ago.\n\n**Can we make it go faster?**\n\nBefore a lot of art got involved with NFTs there were a lot of people using ethereum for other applications. These people have been asking the same question for years and have been very frustrated at the pace of progress. In fact some pushing did get some changes in pace in various ways, including taking a better approach to risks than simply going very slow so as to avoid breaking things ‚Äî the major concern from devs. If something went wrong it would destroy the project.\n\nAt this point however, I don‚Äôt think things can go any faster except by adding more risks. Certainly pressurising developers who already desperately want to be done isn‚Äôt helpful.\n\n**Why hasn‚Äôt it started?**\n\n**It has!** The first component of Ethereum 2.0 has already been released. You can‚Äôt use NFTs on there yet though as more stages are required. This is all documented in the links below. Some even have diagrams :)\n\n**What‚Äôs the incentive for people to move to Ethereum 2.0?**\n\nIt‚Äôs an upgrade, it‚Äôs automatic.\n\nPeople aren‚Äôt using Ethereum because it‚Äôs proof of work. It is not a badge of honour. It is not in any way beneficial. People use Ethereum because it‚Äôs (sort of) the best out there with the widest community.\n\nMoving to proof of stake actually rewards everyone who holds Ether, the native currency. They can ‚Äòstake‚Äô it to earn ‚Äòinterest‚Äô instead of the current model where that ‚Äòinterest‚Äô is paid to miners, the very same ones who are destroying the environment. Stakers are also the platform‚Äôs users, miners only provide a service and don‚Äôt care about the platform.\n\nIn summary, it‚Äôs profitable, cheaper, faster, better and environmentally friendly. Apart from that, no incentive at all. Please forgive the sarcasm, I‚Äôm British.\n\n**What about all those other Proof of Work chains? People aren‚Äôt moving from those?**\n\nBitcoin, Litecoin and Dogecoin need to deal with this or they will suffer. Virtually every other blockchain, and every modern blockchain of note, uses alternatives to proof of work.\n\nIf you want to do something about blockchain‚Äôs impact on the environment, you should be going for the projects with no intention of changing and not the one leading the way for massively decentralised proof of stake networks.\n\n**Otherwise you are literally shooting the very people doing the work everyone else needs to reduce the environmental impact of blockchains‚Äî the very definition of insanity.**\n\n## Ethereum 2.0 Links\n\nThese links came off a quick google search. I‚Äôm not doing anything you couldn‚Äôt do in 30 seconds. Before you hate on something you don‚Äôt understand, at least do some googling folks.\n\nIf you‚Äôre feeling brave ‚Äî <https://vitalik.ca/>\n\nMore generally:\n\nThe next person who asks if Ethereum is serious about moving to proof of stake? Send them this.\n\n![](https://miro.medium.com/max/1464/1\\*EPuCnixM2PNL-Yy05CU0Fg.png)\n", "timestamp": 1621619818, "digest": "oNFV5ga6Yow1mqUuS1UApHEP_U3SIWBgq43D_lCUcmw", "contributor": "0x841fF85B6873d7bfB712C8f7A347C774355b6EC3"}
{"id": "Jw7B9r8T-D9ZMLW_7V17iLRP7RB2Ya1TxegOzGVATIo", "title": "Touching Holograms - Microsoft Design - Medium", "body": "## How the Microsoft Mixed Reality Studios explored more immersive interactions\n\n[![Microsoft Design](https://miro.medium.com/fit/c/96/96/1\\*QxJBzpwHk44170qJ4bu7Ng.png)](https://medium.com/@MicrosoftDesign?source=post_page-----e286ac1fb11a--------------------------------)\n\nBy [Oscar Salandin](https://www.oscarsalandin.com/)\n\n‚ÄúCan I flick it?‚Äù\n\nWe were often asked questions like this when users were testing our immersive interaction prototypes on HoloLens 2. Hologram interactions based on simulation and emergence, rather than individual features, can lead to interesting test scenarios.\n\nThe honest answer was, ‚ÄúI don‚Äôt know, but try it.‚Äù\n\nThis video shows a user interacting directly with holograms using their hands, as they would with real objects - holding, pushing, throwing and catching the cubes.\n\n## What if you could treat holograms just like real objects?\n\nYou wouldn‚Äôt need to explain to users the specific steps of interacting with a virtual object. You could just ask them to ‚Äúpick it up‚Äù or ‚Äúput it over there,‚Äù and they would do just that.\n\nWe could fluently communicate and play with virtual objects with our eyes and hands in the language we are used to.\n\nI saw this happen when we introduced a self-declared technophobe to our physical interaction prototype on HoloLens 2 for the first time. She proceeded to smile and play with a virtual cube, dancing with the holograms for several minutes (literally).\n\nWith articulated hand tracking, eye-gaze tracking, and an increased field of view, HoloLens 2 opens new opportunities for users and interaction designers alike. As designers, we aimed to use these inputs and outputs to push immersion further, allowing people to interact and play with holograms in the same physical way that they do with real objects.\n\nThis video depicts the user‚Äôs hands and fingers, physically simulated as spheres, which change color based on their speed and contact with objects.\n\n## Digital hand twin\n\nHow can we make interactions more natural? We started with some laws of nature and built the interactions from the bottom up. When you break it down, interactions like grab, push, and throw are all made up of the same physical concepts: momentum, collision, friction, and gravity.\n\nReal-time physics engines are a key part of many video games, from the Half-Life series to Gang Beasts and Totally Accurate Battle Simulator. Just as these games use physics engines to handle open-ended interactions between virtual objects, we can use physics engines to model interactions between a user and a virtual object.\n\nAs articulated hand tracking with HoloLens 2 gives us the pose of a hand, we can construct a physically simulated twin of your hand in the virtual world by replicating the positions, velocities, and momentum of different parts of the hand. When this virtual hand interacts with virtual objects, the physics engine simulates the outcome, applying momentum, collision, friction, and gravity. These elements add up to grasp, throw, flick, or any other hand-object interaction you can think of.\n\nIn video games, the physics engine is a completely controlled virtual environment. This is different in Mixed Reality, as there is both a simulated physics engine and a physical reality, which need to interact together. An important law in physics simulation is Newton‚Äôs third law of motion, which states, ‚ÄúFor every action in nature, there is an equal and opposite reaction,‚Äù however, we cannot create these reactions in the physical world, as we cannot apply real force to the user‚Äôs hand. This results in the problem of a missing sense ‚Äî the sense of touch, also known as haptic feedback.\n\n## Compensating for missing senses\n\nNo matter how realistic we make these experiences *look*, people still can‚Äôt actually *feel *holograms. HoloLens 2 does not simulate the sense of touch, a key part of hand interactions with objects. Touch provides constant feedback when interacting with an object, so the missing touch sensation can make objects seem ghostly during interactions.\n\nTo design around this, we must over-communicate with the senses that we do have access to: vision and sound. When a user touches and releases an object, we play a sound, and the object lights up to strongly communicate this to the user.\n\nPhysical interactions between objects are two-way, with both objects influencing each other. We cannot make virtual objects physically influence your hand through touch, but we can use light to show a relationship between the object and your hand.\n\nIn this video, virtual light is cast from the cubes onto the real hands and table, helping to illustrate proximity.\n\nHolding a bright object will cast light onto and through your hand, giving you more feedback about the interaction between your hand and the object. Adding this subtle effect to the virtual hand has a surprisingly strong effect on the realism of the interaction, giving information about depth, proximity, and direction. This lighting effect blurs the line between digital and physical, as the hand you are now looking at is a composite of the lighting from both the user‚Äôs real environment and virtual objects.\n\nSome users described that holding a particularly bright red glowing hologram and seeing its effect on their skin made their hand feel warm, even though they knew that it could not really be heating up.\n\nWhile these designs improve the experience of handling virtual objects, there is still some ghostliness to the interaction, as there is no haptic feedback.\n\n## Bending the rules to accommodate users\n\nNow that these virtual objects behave in a more physical way, testing with users revealed some unwanted physical interactions creeping in, too. Walking large distances to pick up objects and reaching down to the floor to collect dropped items are real-world annoyances that we do not need to tolerate in the virtual world. For users with different abilities, these types of interactions range from annoying to impossible.\n\nWe could mitigate the negative effects of dropping a virtual object by disabling gravity. But without gravity, objects float away from the surfaces you place them on, like on the International Space Station.\n\n*This video depicts a behaviour we developed called ‚ÄúSurface Gravity.‚Äù When there is no real-life surface to fall onto, objects will, instead, float in the air.*\n\nTo improve the negative interaction of accidentally dropping objects, we introduced the concept of ‚Äúsurface gravity,‚Äù giving objects gravity when there is a surface below to fall onto. When there is no surface, objects float in the air where you leave them.\n\nThis video shows a gesture we created called ‚ÄúTelekinesis,‚Äù which lets users summon and control objects which are out of reach.\n\nDuring testing, one user threw an object up high, where it floated until they attempted to climb on top of a precarious bar stool to reach it. This highlighted a problem for users trying to access far objects, as this person was putting themselves in physical danger for a virtual object.\n\nTo improve the experience of reaching faraway objects, we introduced a ‚Äútelekinesis‚Äù gesture. This allows people to summon objects to their hand when they are far away. While telekinesis is not part of real physical interactions, it is a gesture many people have seen or imitated from popular media like Star Wars and Matilda. Here, we use a combination of eye-gaze and hand tracking to let the user confidently move an object without touching it.\n\n## Emergent interactions\n\nThe immersion found in this prototype is a glimpse into a world of tangible Mixed Reality interactions, and simulated physicality could change how we use and understand every digital experience.\n\nImagine, when shopping online, you could hold the blanket you are viewing, throw it over your sofa to see how it looks, then auto-fold it and drop it into your shopping basket.\n\nHow could the feeling of ownership change if you could hold a music album in your hands, put it on your shelf, throw it to your speaker to play, or burn a mixtape and hand it to a friend?\n\nWhat new art and play could emerge if our digital products are more open to undesigned interactions, like record scratching on vinyl or folding a document into a paper plane?\n\nHow could we change how we educate, if you could teach gravity by pushing a miniature planet into orbit around a sun, or unroll the Magna Carta and hold it in your hands?\n\nWith our prototypes, we contribute towards a vision of more immersive, playful and open-ended interactions to cultivate the inquisitive and creative nature of people to explore and interrogate virtual experiences. It is the beginning of an exciting journey to discover how these types of new interactions come to life across diverse and multifaceted user experiences and use cases.\n", "timestamp": 1621619591, "digest": "q4A0zw_Rs8R75CkwBFtTR4mUdNrOUOGzVo19_Jhj1e8", "contributor": "0x841fF85B6873d7bfB712C8f7A347C774355b6EC3"}
{"id": "n5SD6yPHF30qqUt5VbzXtdC_p73qzoXqN_-bpHVywpA", "title": "Touching Holograms - Microsoft Design - Medium", "body": "## How the Microsoft Mixed Reality Studios explored more immersive interactions\n\n‚ÄúCan I flick it?‚Äù\n\nWe were often asked questions like this when users were testing our immersive interaction prototypes on HoloLens 2. Hologram interactions based on simulation and emergence, rather than individual features, can lead to interesting test scenarios.\n\nThe honest answer was, ‚ÄúI don‚Äôt know, but try it.‚Äù\n\nThis video shows a user interacting directly with holograms using their hands, as they would with real objects - holding, pushing, throwing and catching the cubes.\n\n## What if you could treat holograms just like real objects?\n\nYou wouldn‚Äôt need to explain to users the specific steps of interacting with a virtual object. You could just ask them to ‚Äúpick it up‚Äù or ‚Äúput it over there,‚Äù and they would do just that.\n\nWe could fluently communicate and play with virtual objects with our eyes and hands in the language we are used to.\n\nI saw this happen when we introduced a self-declared technophobe to our physical interaction prototype on HoloLens 2 for the first time. She proceeded to smile and play with a virtual cube, dancing with the holograms for several minutes (literally).\n\nWith articulated hand tracking, eye-gaze tracking, and an increased field of view, HoloLens 2 opens new opportunities for users and interaction designers alike. As designers, we aimed to use these inputs and outputs to push immersion further, allowing people to interact and play with holograms in the same physical way that they do with real objects.\n\nThis video depicts the user‚Äôs hands and fingers, physically simulated as spheres, which change color based on their speed and contact with objects.\n\n## Digital hand twin\n\nHow can we make interactions more natural? We started with some laws of nature and built the interactions from the bottom up. When you break it down, interactions like grab, push, and throw are all made up of the same physical concepts: momentum, collision, friction, and gravity.\n\nReal-time physics engines are a key part of many video games, from the Half-Life series to Gang Beasts and Totally Accurate Battle Simulator. Just as these games use physics engines to handle open-ended interactions between virtual objects, we can use physics engines to model interactions between a user and a virtual object.\n\nAs articulated hand tracking with HoloLens 2 gives us the pose of a hand, we can construct a physically simulated twin of your hand in the virtual world by replicating the positions, velocities, and momentum of different parts of the hand. When this virtual hand interacts with virtual objects, the physics engine simulates the outcome, applying momentum, collision, friction, and gravity. These elements add up to grasp, throw, flick, or any other hand-object interaction you can think of.\n\nIn video games, the physics engine is a completely controlled virtual environment. This is different in Mixed Reality, as there is both a simulated physics engine and a physical reality, which need to interact together. An important law in physics simulation is Newton‚Äôs third law of motion, which states, ‚ÄúFor every action in nature, there is an equal and opposite reaction,‚Äù however, we cannot create these reactions in the physical world, as we cannot apply real force to the user‚Äôs hand. This results in the problem of a missing sense ‚Äî the sense of touch, also known as haptic feedback.\n\n## Compensating for missing senses\n\nNo matter how realistic we make these experiences *look*, people still can‚Äôt actually *feel *holograms. HoloLens 2 does not simulate the sense of touch, a key part of hand interactions with objects. Touch provides constant feedback when interacting with an object, so the missing touch sensation can make objects seem ghostly during interactions.\n\nTo design around this, we must over-communicate with the senses that we do have access to: vision and sound. When a user touches and releases an object, we play a sound, and the object lights up to strongly communicate this to the user.\n\nPhysical interactions between objects are two-way, with both objects influencing each other. We cannot make virtual objects physically influence your hand through touch, but we can use light to show a relationship between the object and your hand.\n\nIn this video, virtual light is cast from the cubes onto the real hands and table, helping to illustrate proximity.\n\nHolding a bright object will cast light onto and through your hand, giving you more feedback about the interaction between your hand and the object. Adding this subtle effect to the virtual hand has a surprisingly strong effect on the realism of the interaction, giving information about depth, proximity, and direction. This lighting effect blurs the line between digital and physical, as the hand you are now looking at is a composite of the lighting from both the user‚Äôs real environment and virtual objects.\n\nSome users described that holding a particularly bright red glowing hologram and seeing its effect on their skin made their hand feel warm, even though they knew that it could not really be heating up.\n\nWhile these designs improve the experience of handling virtual objects, there is still some ghostliness to the interaction, as there is no haptic feedback.\n\n## Bending the rules to accommodate users\n\nNow that these virtual objects behave in a more physical way, testing with users revealed some unwanted physical interactions creeping in, too. Walking large distances to pick up objects and reaching down to the floor to collect dropped items are real-world annoyances that we do not need to tolerate in the virtual world. For users with different abilities, these types of interactions range from annoying to impossible.\n\nWe could mitigate the negative effects of dropping a virtual object by disabling gravity. But without gravity, objects float away from the surfaces you place them on, like on the International Space Station.\n\n*This video depicts a behaviour we developed called ‚ÄúSurface Gravity.‚Äù When there is no real-life surface to fall onto, objects will, instead, float in the air.*\n\nTo improve the negative interaction of accidentally dropping objects, we introduced the concept of ‚Äúsurface gravity,‚Äù giving objects gravity when there is a surface below to fall onto. When there is no surface, objects float in the air where you leave them.\n\nThis video shows a gesture we created called ‚ÄúTelekinesis,‚Äù which lets users summon and control objects which are out of reach.\n\nDuring testing, one user threw an object up high, where it floated until they attempted to climb on top of a precarious bar stool to reach it. This highlighted a problem for users trying to access far objects, as this person was putting themselves in physical danger for a virtual object.\n\nTo improve the experience of reaching faraway objects, we introduced a ‚Äútelekinesis‚Äù gesture. This allows people to summon objects to their hand when they are far away. While telekinesis is not part of real physical interactions, it is a gesture many people have seen or imitated from popular media like Star Wars and Matilda. Here, we use a combination of eye-gaze and hand tracking to let the user confidently move an object without touching it.\n\n## Emergent interactions\n\nThe immersion found in this prototype is a glimpse into a world of tangible Mixed Reality interactions, and simulated physicality could change how we use and understand every digital experience.\n\nImagine, when shopping online, you could hold the blanket you are viewing, throw it over your sofa to see how it looks, then auto-fold it and drop it into your shopping basket.\n\nHow could the feeling of ownership change if you could hold a music album in your hands, put it on your shelf, throw it to your speaker to play, or burn a mixtape and hand it to a friend?\n\nWhat new art and play could emerge if our digital products are more open to undesigned interactions, like record scratching on vinyl or folding a document into a paper plane?\n\nHow could we change how we educate, if you could teach gravity by pushing a miniature planet into orbit around a sun, or unroll the Magna Carta and hold it in your hands?\n\nWith our prototypes, we contribute towards a vision of more immersive, playful and open-ended interactions to cultivate the inquisitive and creative nature of people to explore and interrogate virtual experiences. It is the beginning of an exciting journey to discover how these types of new interactions come to life across diverse and multifaceted user experiences and use cases.\n", "timestamp": 1621619956, "digest": "q4A0zw_Rs8R75CkwBFtTR4mUdNrOUOGzVo19_Jhj1e8", "contributor": "0x841fF85B6873d7bfB712C8f7A347C774355b6EC3"}
{"id": "xTB6rH7l5ob7p8X0Fdq_RtpniknX7xGjWvcYuwRnV9s", "title": "Touching Holograms - Microsoft Design - Medium", "body": "## How the Microsoft Mixed Reality Studios explored more immersive interactions\n\n‚ÄúCan I flick it?‚Äù\n\nWe were often asked questions like this when users were testing our immersive interaction prototypes on HoloLens 2. Hologram interactions based on simulation and emergence, rather than individual features, can lead to interesting test scenarios.\n\nThe honest answer was, ‚ÄúI don‚Äôt know, but try it.‚Äù\n\nThis video shows a user interacting directly with holograms using their hands, as they would with real objects - holding, pushing, throwing and catching the cubes.\n\n## What if you could treat holograms just like real objects?\n\nYou wouldn‚Äôt need to explain to users the specific steps of interacting with a virtual object. You could just ask them to ‚Äúpick it up‚Äù or ‚Äúput it over there,‚Äù and they would do just that.\n\nWe could fluently communicate and play with virtual objects with our eyes and hands in the language we are used to.\n\nI saw this happen when we introduced a self-declared technophobe to our physical interaction prototype on HoloLens 2 for the first time. She proceeded to smile and play with a virtual cube, dancing with the holograms for several minutes (literally).\n\nWith articulated hand tracking, eye-gaze tracking, and an increased field of view, HoloLens 2 opens new opportunities for users and interaction designers alike. As designers, we aimed to use these inputs and outputs to push immersion further, allowing people to interact and play with holograms in the same physical way that they do with real objects.\n\nThis video depicts the user‚Äôs hands and fingers, physically simulated as spheres, which change color based on their speed and contact with objects.\n\n## Digital hand twin\n\nHow can we make interactions more natural? We started with some laws of nature and built the interactions from the bottom up. When you break it down, interactions like grab, push, and throw are all made up of the same physical concepts: momentum, collision, friction, and gravity.\n\nReal-time physics engines are a key part of many video games, from the Half-Life series to Gang Beasts and Totally Accurate Battle Simulator. Just as these games use physics engines to handle open-ended interactions between virtual objects, we can use physics engines to model interactions between a user and a virtual object.\n\nAs articulated hand tracking with HoloLens 2 gives us the pose of a hand, we can construct a physically simulated twin of your hand in the virtual world by replicating the positions, velocities, and momentum of different parts of the hand. When this virtual hand interacts with virtual objects, the physics engine simulates the outcome, applying momentum, collision, friction, and gravity. These elements add up to grasp, throw, flick, or any other hand-object interaction you can think of.\n\nIn video games, the physics engine is a completely controlled virtual environment. This is different in Mixed Reality, as there is both a simulated physics engine and a physical reality, which need to interact together. An important law in physics simulation is Newton‚Äôs third law of motion, which states, ‚ÄúFor every action in nature, there is an equal and opposite reaction,‚Äù however, we cannot create these reactions in the physical world, as we cannot apply real force to the user‚Äôs hand. This results in the problem of a missing sense ‚Äî the sense of touch, also known as haptic feedback.\n\n## Compensating for missing senses\n\nNo matter how realistic we make these experiences *look*, people still can‚Äôt actually *feel *holograms. HoloLens 2 does not simulate the sense of touch, a key part of hand interactions with objects. Touch provides constant feedback when interacting with an object, so the missing touch sensation can make objects seem ghostly during interactions.\n\nTo design around this, we must over-communicate with the senses that we do have access to: vision and sound. When a user touches and releases an object, we play a sound, and the object lights up to strongly communicate this to the user.\n\nPhysical interactions between objects are two-way, with both objects influencing each other. We cannot make virtual objects physically influence your hand through touch, but we can use light to show a relationship between the object and your hand.\n\nIn this video, virtual light is cast from the cubes onto the real hands and table, helping to illustrate proximity.\n\nHolding a bright object will cast light onto and through your hand, giving you more feedback about the interaction between your hand and the object. Adding this subtle effect to the virtual hand has a surprisingly strong effect on the realism of the interaction, giving information about depth, proximity, and direction. This lighting effect blurs the line between digital and physical, as the hand you are now looking at is a composite of the lighting from both the user‚Äôs real environment and virtual objects.\n\nSome users described that holding a particularly bright red glowing hologram and seeing its effect on their skin made their hand feel warm, even though they knew that it could not really be heating up.\n\nWhile these designs improve the experience of handling virtual objects, there is still some ghostliness to the interaction, as there is no haptic feedback.\n\n## Bending the rules to accommodate users\n\nNow that these virtual objects behave in a more physical way, testing with users revealed some unwanted physical interactions creeping in, too. Walking large distances to pick up objects and reaching down to the floor to collect dropped items are real-world annoyances that we do not need to tolerate in the virtual world. For users with different abilities, these types of interactions range from annoying to impossible.\n\nWe could mitigate the negative effects of dropping a virtual object by disabling gravity. But without gravity, objects float away from the surfaces you place them on, like on the International Space Station.\n\n*This video depicts a behaviour we developed called ‚ÄúSurface Gravity.‚Äù When there is no real-life surface to fall onto, objects will, instead, float in the air.*\n\nTo improve the negative interaction of accidentally dropping objects, we introduced the concept of ‚Äúsurface gravity,‚Äù giving objects gravity when there is a surface below to fall onto. When there is no surface, objects float in the air where you leave them.\n\nThis video shows a gesture we created called ‚ÄúTelekinesis,‚Äù which lets users summon and control objects which are out of reach.\n\nDuring testing, one user threw an object up high, where it floated until they attempted to climb on top of a precarious bar stool to reach it. This highlighted a problem for users trying to access far objects, as this person was putting themselves in physical danger for a virtual object.\n\nTo improve the experience of reaching faraway objects, we introduced a ‚Äútelekinesis‚Äù gesture. This allows people to summon objects to their hand when they are far away. While telekinesis is not part of real physical interactions, it is a gesture many people have seen or imitated from popular media like Star Wars and Matilda. Here, we use a combination of eye-gaze and hand tracking to let the user confidently move an object without touching it.\n\n## Emergent interactions\n\nThe immersion found in this prototype is a glimpse into a world of tangible Mixed Reality interactions, and simulated physicality could change how we use and understand every digital experience.\n\nImagine, when shopping online, you could hold the blanket you are viewing, throw it over your sofa to see how it looks, then auto-fold it and drop it into your shopping basket.\n\nHow could the feeling of ownership change if you could hold a music album in your hands, put it on your shelf, throw it to your speaker to play, or burn a mixtape and hand it to a friend?\n\nWhat new art and play could emerge if our digital products are more open to undesigned interactions, like record scratching on vinyl or folding a document into a paper plane?\n\nHow could we change how we educate, if you could teach gravity by pushing a miniature planet into orbit around a sun, or unroll the Magna Carta and hold it in your hands?\n\nWith our prototypes, we contribute towards a vision of more immersive, playful and open-ended interactions to cultivate the inquisitive and creative nature of people to explore and interrogate virtual experiences. It is the beginning of an exciting journey to discover how these types of new interactions come to life across diverse and multifaceted user experiences and use cases.\n", "timestamp": 1621619969, "digest": "q4A0zw_Rs8R75CkwBFtTR4mUdNrOUOGzVo19_Jhj1e8", "contributor": "0x841fF85B6873d7bfB712C8f7A347C774355b6EC3"}
{"id": "qhaT04i8U4i4cRtMAV_13g7RsD6LGYfJSVL_dkZuXog", "title": "Touching Holograms - Microsoft Design - Medium", "body": "## How the Microsoft Mixed Reality Studios explored more immersive interactions\n\n‚ÄúCan I flick it?‚Äù\n\nWe were often asked questions like this when users were testing our immersive interaction prototypes on HoloLens 2. Hologram interactions based on simulation and emergence, rather than individual features, can lead to interesting test scenarios.\n\nThe honest answer was, ‚ÄúI don‚Äôt know, but try it.‚Äù\n\nThis video shows a user interacting directly with holograms using their hands, as they would with real objects - holding, pushing, throwing and catching the cubes.\n\n## What if you could treat holograms just like real objects?\n\nYou wouldn‚Äôt need to explain to users the specific steps of interacting with a virtual object. You could just ask them to ‚Äúpick it up‚Äù or ‚Äúput it over there,‚Äù and they would do just that.\n\nWe could fluently communicate and play with virtual objects with our eyes and hands in the language we are used to.\n\nI saw this happen when we introduced a self-declared technophobe to our physical interaction prototype on HoloLens 2 for the first time. She proceeded to smile and play with a virtual cube, dancing with the holograms for several minutes (literally).\n\nWith articulated hand tracking, eye-gaze tracking, and an increased field of view, HoloLens 2 opens new opportunities for users and interaction designers alike. As designers, we aimed to use these inputs and outputs to push immersion further, allowing people to interact and play with holograms in the same physical way that they do with real objects.\n\nThis video depicts the user‚Äôs hands and fingers, physically simulated as spheres, which change color based on their speed and contact with objects.\n\n## Digital hand twin\n\nHow can we make interactions more natural? We started with some laws of nature and built the interactions from the bottom up. When you break it down, interactions like grab, push, and throw are all made up of the same physical concepts: momentum, collision, friction, and gravity.\n\nReal-time physics engines are a key part of many video games, from the Half-Life series to Gang Beasts and Totally Accurate Battle Simulator. Just as these games use physics engines to handle open-ended interactions between virtual objects, we can use physics engines to model interactions between a user and a virtual object.\n\nAs articulated hand tracking with HoloLens 2 gives us the pose of a hand, we can construct a physically simulated twin of your hand in the virtual world by replicating the positions, velocities, and momentum of different parts of the hand. When this virtual hand interacts with virtual objects, the physics engine simulates the outcome, applying momentum, collision, friction, and gravity. These elements add up to grasp, throw, flick, or any other hand-object interaction you can think of.\n\nIn video games, the physics engine is a completely controlled virtual environment. This is different in Mixed Reality, as there is both a simulated physics engine and a physical reality, which need to interact together. An important law in physics simulation is Newton‚Äôs third law of motion, which states, ‚ÄúFor every action in nature, there is an equal and opposite reaction,‚Äù however, we cannot create these reactions in the physical world, as we cannot apply real force to the user‚Äôs hand. This results in the problem of a missing sense ‚Äî the sense of touch, also known as haptic feedback.\n\n## Compensating for missing senses\n\nNo matter how realistic we make these experiences *look*, people still can‚Äôt actually *feel *holograms. HoloLens 2 does not simulate the sense of touch, a key part of hand interactions with objects. Touch provides constant feedback when interacting with an object, so the missing touch sensation can make objects seem ghostly during interactions.\n\nTo design around this, we must over-communicate with the senses that we do have access to: vision and sound. When a user touches and releases an object, we play a sound, and the object lights up to strongly communicate this to the user.\n\nPhysical interactions between objects are two-way, with both objects influencing each other. We cannot make virtual objects physically influence your hand through touch, but we can use light to show a relationship between the object and your hand.\n\nIn this video, virtual light is cast from the cubes onto the real hands and table, helping to illustrate proximity.\n\nHolding a bright object will cast light onto and through your hand, giving you more feedback about the interaction between your hand and the object. Adding this subtle effect to the virtual hand has a surprisingly strong effect on the realism of the interaction, giving information about depth, proximity, and direction. This lighting effect blurs the line between digital and physical, as the hand you are now looking at is a composite of the lighting from both the user‚Äôs real environment and virtual objects.\n\nSome users described that holding a particularly bright red glowing hologram and seeing its effect on their skin made their hand feel warm, even though they knew that it could not really be heating up.\n\nWhile these designs improve the experience of handling virtual objects, there is still some ghostliness to the interaction, as there is no haptic feedback.\n\n## Bending the rules to accommodate users\n\nNow that these virtual objects behave in a more physical way, testing with users revealed some unwanted physical interactions creeping in, too. Walking large distances to pick up objects and reaching down to the floor to collect dropped items are real-world annoyances that we do not need to tolerate in the virtual world. For users with different abilities, these types of interactions range from annoying to impossible.\n\nWe could mitigate the negative effects of dropping a virtual object by disabling gravity. But without gravity, objects float away from the surfaces you place them on, like on the International Space Station.\n\n*This video depicts a behaviour we developed called ‚ÄúSurface Gravity.‚Äù When there is no real-life surface to fall onto, objects will, instead, float in the air.*\n\nTo improve the negative interaction of accidentally dropping objects, we introduced the concept of ‚Äúsurface gravity,‚Äù giving objects gravity when there is a surface below to fall onto. When there is no surface, objects float in the air where you leave them.\n\nThis video shows a gesture we created called ‚ÄúTelekinesis,‚Äù which lets users summon and control objects which are out of reach.\n\nDuring testing, one user threw an object up high, where it floated until they attempted to climb on top of a precarious bar stool to reach it. This highlighted a problem for users trying to access far objects, as this person was putting themselves in physical danger for a virtual object.\n\nTo improve the experience of reaching faraway objects, we introduced a ‚Äútelekinesis‚Äù gesture. This allows people to summon objects to their hand when they are far away. While telekinesis is not part of real physical interactions, it is a gesture many people have seen or imitated from popular media like Star Wars and Matilda. Here, we use a combination of eye-gaze and hand tracking to let the user confidently move an object without touching it.\n\n## Emergent interactions\n\nThe immersion found in this prototype is a glimpse into a world of tangible Mixed Reality interactions, and simulated physicality could change how we use and understand every digital experience.\n\nImagine, when shopping online, you could hold the blanket you are viewing, throw it over your sofa to see how it looks, then auto-fold it and drop it into your shopping basket.\n\nHow could the feeling of ownership change if you could hold a music album in your hands, put it on your shelf, throw it to your speaker to play, or burn a mixtape and hand it to a friend?\n\nWhat new art and play could emerge if our digital products are more open to undesigned interactions, like record scratching on vinyl or folding a document into a paper plane?\n\nHow could we change how we educate, if you could teach gravity by pushing a miniature planet into orbit around a sun, or unroll the Magna Carta and hold it in your hands?\n\nWith our prototypes, we contribute towards a vision of more immersive, playful and open-ended interactions to cultivate the inquisitive and creative nature of people to explore and interrogate virtual experiences. It is the beginning of an exciting journey to discover how these types of new interactions come to life across diverse and multifaceted user experiences and use cases.\n", "timestamp": 1621619997, "digest": "q4A0zw_Rs8R75CkwBFtTR4mUdNrOUOGzVo19_Jhj1e8", "contributor": "0x841fF85B6873d7bfB712C8f7A347C774355b6EC3"}
{"id": "AJKIrum8bJHc8vPj64Om2eVinZ5JwoU93qEONXqwPi0", "title": "A quick test", "body": "Oh whats up!", "timestamp": 1621620856, "digest": "s0KcBxBEins4Zp9200NKMaJzWZweC6OODZhMySfD088", "contributor": "0xFf37A713c920F6e94043D10c1230e30B13F4d500"}
{"id": "M9PVc3U-NaY3FZGYvB9z3Eb5tEgHIS6bG1oAu49lIyw", "title": "Test entry", "body": "Test", "timestamp": 1621634624, "digest": "k7afJrse-xh14z1cHuD85w1PnrqGNixkspGee5R6h-E", "contributor": "0x4B71D61591a054C498bdb410AF99702689e649cc"}
{"id": "4PnTt5OC8f5x43RJizosOjSbXXu-BN8gXKBlV3qYmMo", "title": "Edition Test", "body": "[Edition Test](edition://example)", "timestamp": 1621636489, "digest": "oNFV5ga6Yow1mqUuS1UApHEP_U3SIWBgq43D_lCUcmw", "contributor": "0x841fF85B6873d7bfB712C8f7A347C774355b6EC3"}
{"id": "HFmsKoQJngI9NdIRvhsM1MF98E3Op6FRIq-AQCYrVjY", "title": "Edition Test", "body": "[Edition Test](edition://example)", "timestamp": 1621639979, "digest": "oNFV5ga6Yow1mqUuS1UApHEP_U3SIWBgq43D_lCUcmw", "contributor": "0x841fF85B6873d7bfB712C8f7A347C774355b6EC3"}
{"id": "1wwk3WnucVdjmOJ128q_CbXS0MUlc5tDmV20rm4q31w", "title": "Test", "body": "test", "timestamp": 1621648480, "digest": "zo6JGTWjTCi84q3W3XXWDbZTh-S0SPAo6xa5SxJUGAQ", "contributor": "0x4B71D61591a054C498bdb410AF99702689e649cc"}
{"id": "vCIE6zwtSA4xRduZggXBa2FQeOxpfU_QOrgXseDAilc", "title": "CANON ‚Äî \"Island\" ‚®ä Auction d:01", "body": "[Token #3169](auction://0xabEFBc9fD2F806065b4f3C237d4b59D9A97Bcac7?network=mainnet&tokenId=3169)", "timestamp": 1621649781, "digest": "NgAsoP5Txw2MwQqcxYfqTxnC2j0DSrBDc8akVZ-gDmk", "contributor": "0x5090c4Fead5Be112b643BC75d61bF42339675448"}
